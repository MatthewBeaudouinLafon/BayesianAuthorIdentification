{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Generation\n",
    "In this notebook, we generate the necessary Markov Chains for each author which will be used as likelihood functions during the identification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import sys\n",
    "import re\n",
    "from pickle import dump\n",
    "\n",
    "def pickleDump(filename, todump):\n",
    "    out = open(filename, 'wb+')\n",
    "    for d in todump:\n",
    "        dump(d, out)\n",
    "    out.close()\n",
    "    \n",
    "class MarkovChain():\n",
    "    \"\"\"\n",
    "    Markov Chain class. \n",
    "    chain:       nested dictionary representing the number of occurences of a word given the previous word.\n",
    "    wordCount:   dictionary of the number of total number of words (value) that have occured after the previous word (key).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, author):\n",
    "        \"\"\"\n",
    "        Parameter: \n",
    "            - author: name of author (string)\n",
    "        \"\"\"\n",
    "        self.author = author\n",
    "        self.chain = {'*': {}}\n",
    "        self.wordCount = {'*': 0}\n",
    "    \n",
    "    def addWord(self, prevWord, word):\n",
    "        \"\"\"\n",
    "        Add a word to the Markov Chain.\n",
    "        Takes the previous word and the current word as strings\n",
    "        \"\"\"\n",
    "        self.chain[prevWord][word] = 1 + self.chain[prevWord].get(word, 0)\n",
    "        self.wordCount[prevWord]= 1 + self.wordCount.get(prevWord, 0)\n",
    "    \n",
    "        # When encountering a new word, add it to the prefix dictionary\n",
    "        if not self.chain.get(word):\n",
    "            self.chain[word] = {}\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        \"\"\"\n",
    "        Process a \"sentence\" to produce a Markov Chain. Takes a sentence as a list of lowercase words.\n",
    "        NO ASTERISKS. SERIOUSLY.\n",
    "        \"\"\"\n",
    "        # '*' represents the beginning of a sentence in the chain. \n",
    "        # This way, we can determine the probability of a word starting a sentence\n",
    "        sentence = ['*'] + sentence\n",
    "        if len(sentence) > 1:\n",
    "            for i in [i + 1 for i in range(len(sentence)-1)]: # Start at the second word\n",
    "                self.addWord(sentence[i-1], sentence[i])\n",
    "        \n",
    "    def getProb(self, prevWord, word):\n",
    "        \"\"\"\n",
    "        Return the probability of getting word given prevWord.\n",
    "        Takes two strings.\n",
    "        \"\"\"\n",
    "        return self.chain[prevWord][word]/self.wordCount[prevWord]\n",
    "    \n",
    "def processGutenberg(fileName, author, make=True):\n",
    "    \"\"\"\n",
    "    Process a Gutenberg text file.\n",
    "    fileName: string\n",
    "    author: string\n",
    "    returns a markovChain object.\n",
    "    \"\"\"\n",
    "    f = open(fileName + '.txt')\n",
    "    \n",
    "    #Skip to the beginning of the actual text\n",
    "    for line in f:\n",
    "        if line.startswith(\"*** START OF THIS PROJECT\"):\n",
    "            break\n",
    "    \n",
    "    text = ''\n",
    "    \n",
    "    # Put the text into one big string\n",
    "    for line in f:\n",
    "        # Stop when hitting the end of the book\n",
    "        if line.startswith(\"*** END OF THIS PROJECT\"):\n",
    "            break\n",
    "        \n",
    "        text += line + ' '\n",
    "        \n",
    "    sentences = re.split('[.?!]', text) # Seperate text into a list of sentences sentence\n",
    "    \n",
    "    listOSentences = []\n",
    "    for sentence in sentences:\n",
    "        # Make all words lowercase and strip off punctuation\n",
    "        sentenceList = ''.join(char for char in sentence if char in set(string.ascii_letters + string.digits + ' ')).lower().split()\n",
    "        \n",
    "        if sentenceList != []:\n",
    "            listOSentences.append(sentenceList)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    if make==True:\n",
    "        m = makeMarkov(listOSentences, author)\n",
    "        pickleDump(fileName + '.dat', [m.chain, m.wordCount, m.author])\n",
    "    else:\n",
    "        pickleDump(fileName + '.dat', [listOSentences, author])\n",
    "\n",
    "def makeMarkov(sentenceList, author):\n",
    "    markovChain = MarkovChain(author)\n",
    "    for sentence in sentenceList:\n",
    "        # Process the sentence in the Markov Chain\n",
    "        markovChain.addSentence(sentence)\n",
    "    return markovChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books = [('GreatExpectations', 'Charles Dickens'), ('Frankenstein', 'Mary Shelley'),\n",
    "         ('RomeoAndJuliet', 'Shakespeare'), ('MobyDick', 'Herman Melville'), ('Twilight', 'Stephenie Meyer'),\n",
    "         (\"The Hitch Hiker's Guide to the Galaxy\", 'Douglas Adams')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for book in books:\n",
    "    name, author = book\n",
    "    processGutenberg(name, author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update test Text\n",
    "processGutenberg('testText', 'Unknown', make=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
