{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Identification\n",
    "#### Carl Moser, Matthew Beaudouin-Lafon\n",
    "\n",
    "We did stuff to do things with doodas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from thinkbayes2 import Suite\n",
    "from pickle import load\n",
    "\n",
    "class AuthorId(Suite):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "#     def __init__(self, chainList):\n",
    "#         self.authors = []\n",
    "#         self.chains = []\n",
    "#         self.wordCounts = []\n",
    "        \n",
    "#         for markov in chainList:\n",
    "#             self.authors.append(markov.author)\n",
    "#             self.chains.append(markov.chain)\n",
    "#             self.wordCounts.append(markov.wordCount)\n",
    "                \n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"\n",
    "        data: (string, string)\n",
    "        hypo: (Markov Chain, Word Count dictionary, Author)\n",
    "        \"\"\"\n",
    "        hypoAuthor = hypo\n",
    "        chain, wordCount = markovChains[hypoAuthor]\n",
    "        prevWord, word, dataAuthor = data\n",
    "        \n",
    "        if not (chain.get(prevWord) or chain[prevWord].get(word)):\n",
    "            return 0.01 # It's 0.01 because 0.01 is a number\n",
    "        \n",
    "        return chain[prevWord][word]/float(wordCount[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPickle(fileName):\n",
    "    infile = open(fileName, 'rb+')\n",
    "    chain = load(infile)\n",
    "    wordCount = load(infile)\n",
    "    author = load(infile)\n",
    "    infile.close()\n",
    "    return (chain, wordCount, author)\n",
    "\n",
    "# files = ['Frankenstein', 'GreatExpecations', 'Hamlet', 'MobyDick', 'PierreAmbiguities', 'RomeoAndJuliet']\n",
    "files = ['Frankenstein.dat', 'GreatExp.dat', 'RomeoJuliet.dat']\n",
    "\n",
    "authorId = AuthorId()\n",
    "authorId.markovChains = {}\n",
    "\n",
    "for f in files:\n",
    "    chain, wordCount, author = getPickle(f)\n",
    "    authorId.markovChains[author] = (chain, wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o', 'that', 'this', 'too', 'too', 'solid', 'flesh', 'would', 'melt', 'thaw', 'and', 'resolve', 'itself', 'into', 'a', 'dew']\n"
     ]
    }
   ],
   "source": [
    "f = open('testText.dat')\n",
    "testText = load(f)\n",
    "f.close()\n",
    "print(testText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "    - What to do with words that aren't there?\n",
    "    - \"To\" appears a lot more than other words. Should it be weighed differently?\n",
    "    - Integrate sentence lengths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
